<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dictaphone</title>
    <link rel="icon" type="image/x-icon" href="favicon.ico">
    <style>
        :root {
            --bg-color: #ffffff;
            --text-color: #333333;
            --button-bg: #007bff;
            --button-text: #ffffff;
            --button-hover: #0056b3;
            --button-active: #004085;
            --button-danger: #dc3545;
            --button-danger-hover: #c82333;
            --button-success: #28a745;
            --button-success-hover: #218838;
            --panel-bg: #f8f9fa;
            --border-color: #dee2e6;
            --slider-track: #ddd;
            --slider-thumb: #007bff;
            --meter-bg: #e9ecef;
            --meter-needle: #dc3545;
        }

        [data-theme="dark"] {
            --bg-color: #1a1a1a;
            --text-color: #ffffff;
            --button-bg: #0d6efd;
            --button-text: #ffffff;
            --button-hover: #0b5ed7;
            --button-active: #0a58ca;
            --button-danger: #dc3545;
            --button-danger-hover: #bb2d3b;
            --button-success: #198754;
            --button-success-hover: #157347;
            --panel-bg: #2d2d2d;
            --border-color: #495057;
            --slider-track: #495057;
            --slider-thumb: #0d6efd;
            --meter-bg: #495057;
            --meter-needle: #dc3545;
        }

        * { box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            margin: 0; padding: 10px; background: var(--bg-color); color: var(--text-color);
            transition: background-color .3s ease, color .3s ease; font-size: 18px; line-height:1.5;
        }
        .container { max-width: 800px; margin:0 auto; padding:0; }
        h1 { text-align:center; margin:0 0 15px; font-size:2.5em; font-weight:300; }
        .controls { display:grid; grid-template-columns: repeat(auto-fit,minmax(120px,1fr)); gap:15px; margin-bottom:30px; align-items:center; }
        .skip-controls { display:grid; grid-template-columns: 1fr 1fr; gap:15px; margin-bottom:30px; align-items:center; }
        .button { padding:15px 20px; border:none; border-radius:10px; font-size:16px; font-weight:600; cursor:pointer; transition:all .2s ease; background:var(--button-bg); color:var(--button-text); display:flex; align-items:center; justify-content:center; gap:8px; min-height:60px; touch-action:manipulation; }
        .button:hover { background: var(--button-hover); transform: translateY(-2px); }
        .button:active { background: var(--button-active); transform: translateY(0); }
        .button.danger { background: var(--button-danger); }
        .button.danger:hover { background: var(--button-danger-hover); }
        .button.success { background: var(--button-success); }
        .button.success:hover { background: var(--button-success-hover); }
        .button:disabled { opacity:.6; cursor:not-allowed; transform:none; }
        .button.recording { background: var(--button-danger); animation: pulse 1s infinite; }
        @keyframes pulse { 0%,100% { opacity:1 } 50% { opacity:.7 } }
        .slider-container { margin:30px 0; }
        .slider-wrapper { position:relative; padding:0 30px; }
        .slider { width:100%; height:8px; border-radius:5px; background:var(--slider-track); outline:none; -webkit-appearance:none; appearance:none; cursor:pointer; }
        .slider::-webkit-slider-thumb, .slider::-moz-range-thumb { width:24px; height:24px; border-radius:50%; background:var(--slider-thumb); cursor:pointer; border:2px solid var(--bg-color); box-shadow:0 2px 6px rgba(0,0,0,.2); }
        .time-labels { display:flex; justify-content:space-between; align-items:center; margin-top:10px; font-size:14px; opacity:.8; padding:0 30px; }
        .meter-container { margin:20px 0; text-align:center; }
        .meter { width:200px; height:100px; margin:0 auto; position:relative; background:var(--meter-bg); border-radius:100px 100px 0 0; overflow:hidden; border:3px solid var(--border-color); }

        .meter-needle {
            position: absolute;
            bottom: 0;
            left: 50%;
            width: 1.2em;
            height: 80px;
            background: var(--meter-needle);
            transform-origin: bottom center;
            transform: translateX(-50%) rotate(-90deg);
            transition: transform 0.1s ease;
            border-radius: 0.2em;
            z-index: 1;
        }

        .meter-needle::before {
            content: '';
            position: absolute;
            top: 0;
            left: 50%;
            width: 0.6em;
            height: 100%;
            background: white;
            transform: translateX(-50%);
            border-radius: 0.1em;
            z-index: 2;
        }

        .meter-labels {
            display: flex;
            justify-content: space-between;
            width: 200px;
            margin: 5px auto 0;
            font-size: 12px;
            opacity: 0.7;
        }

        .volume-container {
            margin: 20px 0;
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .volume-label {
            font-weight: 600;
            min-width: 80px;
        }

        .theme-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            background: none;
            border: none;
            font-size: 24px;
            cursor: pointer;
            padding: 10px;
            border-radius: 50%;
            background: var(--panel-bg);
            transition: transform 0.2s ease;
            z-index: 1000;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
        }

        .status {
            text-align: center;
            margin: 20px 0;
            font-size: 18px;
            font-weight: 600;
            min-height: 25px;
        }

        .status.recording {
            color: var(--button-danger);
        }

        .status.playing {
            color: var(--button-success);
        }

        .file-input-wrapper {
            position: relative;
            overflow: hidden;
            display: inline-block;
            width: 100%;
        }

        .file-input-wrapper .button {
            width: 100%;
            height: 100%;
        }

        .file-input {
            position: absolute;
            left: -9999px;
        }

        @media (max-width: 600px) {
            .container {
                padding: 20px;
                margin: 10px;
            }

            .controls {
                grid-template-columns: repeat(2, 1fr);
            }

            .button {
                font-size: 14px;
                padding: 12px 15px;
            }

            h1 {
                font-size: 2em;
            }

            .slider-wrapper {
                padding: 0 20px;
            }

            .time-labels {
                padding: 0 20px;
            }
        }

        .keyboard-shortcuts {
            margin-top: 30px;
            padding: 20px;
            background: var(--panel-bg);
            border-radius: 10px;
            font-size: 14px;
            border: 1px solid var(--border-color);
        }

        .keyboard-shortcuts h3 {
            margin-top: 0;
            margin-bottom: 15px;
        }

        .shortcut-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 10px;
        }

        .shortcut {
            display: flex;
            justify-content: space-between;
        }

        .key {
            background: var(--panel-bg);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: monospace;
            font-size: 12px;
        }

        .transcription-output {
            margin-top: 30px;
            padding: 20px;
            background: var(--panel-bg);
            border-radius: 10px;
            border: 1px solid var(--border-color);
            max-height: 400px;
            overflow-y: auto;
        }

        .transcription-output h3 {
            margin-top: 0;
            margin-bottom: 15px;
            color: var(--text-color);
        }

        .transcription-chunk {
            margin-bottom: 10px;
            padding: 10px;
            background: var(--bg-color);
            border-radius: 8px;
            border: 1px solid var(--border-color);
            font-family: monospace;
            font-size: 14px;
            line-height: 1.4;
        }

        .transcription-timestamp {
            color: var(--button-bg);
            font-weight: 600;
            margin-right: 10px;
        }

        .transcription-progress {
            margin: 15px 0;
            padding: 10px;
            background: var(--panel-bg);
            border-radius: 8px;
            border: 1px solid var(--border-color);
            text-align: center;
        }

        .transcription-progress .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            margin-right: 10px;
            border: 2px solid var(--border-color);
            border-top: 2px solid var(--button-bg);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .modal-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            backdrop-filter: blur(4px);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 2000;
            opacity: 0;
            visibility: hidden;
            transition: opacity 0.3s ease, visibility 0.3s ease;
        }

        .modal-overlay.show {
            opacity: 1;
            visibility: visible;
        }

        .modal-content {
            background: var(--panel-bg);
            border-radius: 15px;
            padding: 30px;
            max-width: 400px;
            width: 90%;
            text-align: center;
            border: 2px solid var(--border-color);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            transform: scale(0.9);
            transition: transform 0.3s ease;
        }

        .modal-overlay.show .modal-content {
            transform: scale(1);
        }

        .modal-title {
            font-size: 1.5em;
            font-weight: 600;
            margin-bottom: 20px;
            color: var(--text-color);
        }

        .modal-progress {
            margin: 20px 0;
        }

        .modal-spinner {
            display: inline-block;
            width: 40px;
            height: 40px;
            margin-bottom: 15px;
            border: 4px solid var(--border-color);
            border-top: 4px solid var(--button-bg);
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        .modal-text {
            font-size: 1.1em;
            color: var(--text-color);
            margin-bottom: 10px;
        }

        .modal-subtext {
            font-size: 0.9em;
            opacity: 0.7;
            color: var(--text-color);
        }
    </style>
    <script type="module">
        // Import Transformers.js
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2/dist/transformers.min.js';
        
        // Disable local models to force downloading from Hugging Face
        env.allowLocalModels = false;
        
        // Suppress ONNX runtime warnings in console
        env.backends.onnx.logLevel = 'error';
        
        // Store the pipeline instance globally
        window.transcriptionPipeline = null;
        window.isTranscriptionModelLoading = false;
    </script>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Dictaphone</h1>
        
        <div class="status" id="status">Ready</div>
        
        <div class="meter-container">
            <div class="meter">
                <div class="meter-needle" id="meterNeedle"></div>
            </div>
            <div class="meter-labels">
                <span>Quiet</span>
                <span>Loud</span>
            </div>
        </div>
        
        <div class="controls">
            <button class="button" id="recordBtn" title="Record (R)">
                <span>üî¥</span> Record
            </button>
            <button class="button" id="pttBtn" title="Push-to-Talk (T)">
                <span>üìª</span> PTT
            </button>
            <button class="button" id="stopBtn" title="Stop (Space)">
                <span>‚èπÔ∏è</span> Stop
            </button>
            <button class="button success" id="playBtn" title="Play (P)">
                <span>‚ñ∂Ô∏è</span> Play
            </button>
        </div>

        <div class="skip-controls">
            <button class="button" id="skipBackBtn" title="Skip Back 10s (Left Arrow)">
                <span>‚è™</span> -10s
            </button>
            <button class="button" id="skipForwardBtn" title="Skip Forward 10s (Right Arrow)">
                <span>‚è©</span> +10s
            </button>
        </div>
        
        <div class="slider-container">
            <div class="slider-wrapper">
                <input type="range" class="slider" id="positionSlider" min="0" max="100" value="0" title="Audio position">
            </div>
            <div class="time-labels">
                <span id="currentTime">0:00</span>
                <span id="totalTime">0:00</span>
            </div>
        </div>
        
        <div class="volume-container">
            <label class="volume-label" for="volumeSlider">Volume:</label>
            <input type="range" class="slider" id="volumeSlider" min="0" max="100" value="75" title="Playback volume">
            <span id="volumeValue">75%</span>
        </div>
        
        <div class="controls">
            <div class="file-input-wrapper">
                <input type="file" class="file-input" id="importFile" accept="audio/*">
                <button class="button" onclick="document.getElementById('importFile').click()" title="Import audio (I)">
                    <span>üìÇ</span> Import
                </button>
            </div>
            <button class="button success" id="exportBtn" title="Export (E)">
                <span>üíæ</span> Export
            </button>
            <button class="button" id="transcribeTextBtn" title="Transcribe to Text (T)">
                <span>üìù</span> Text
            </button>
            <button class="button" id="transcribeJsonBtn" title="Transcribe to JSON (J)">
                <span>üìÑ</span> JSON
            </button>
            <button class="button danger" id="eraseBtn" title="Erase All (Delete)">
                <span>üóëÔ∏è</span> Erase All
            </button>
        </div>
        
        <div class="keyboard-shortcuts">
            <h3>‚å®Ô∏è Keyboard Shortcuts</h3>
            <div class="shortcut-list">
                <div class="shortcut">
                    <span>Record</span>
                    <span class="key">R</span>
                </div>
                <div class="shortcut">
                    <span>Push-to-Talk</span>
                    <span class="key">Hold T</span>
                </div>
                <div class="shortcut">
                    <span>Stop</span>
                    <span class="key">Space</span>
                </div>
                <div class="shortcut">
                    <span>Play</span>
                    <span class="key">P</span>
                </div>
                <div class="shortcut">
                    <span>Skip Back 10s</span>
                    <span class="key">‚Üê</span>
                </div>
                <div class="shortcut">
                    <span>Skip Forward 10s</span>
                    <span class="key">‚Üí</span>
                </div>
                <div class="shortcut">
                    <span>Import</span>
                    <span class="key">I</span>
                </div>
                <div class="shortcut">
                    <span>Export</span>
                    <span class="key">E</span>
                </div>
                <div class="shortcut">
                    <span>Transcribe Text</span>
                    <span class="key">T</span>
                </div>
                <div class="shortcut">
                    <span>Transcribe JSON</span>
                    <span class="key">J</span>
                </div>
                <div class="shortcut">
                    <span>Erase All</span>
                    <span class="key">Del</span>
                </div>
                <div class="shortcut">
                    <span>Theme</span>
                    <span class="key">M</span>
                </div>
            </div>
        </div>

        <div class="privacy-info">
            <h4>üîí Privacy & Data</h4>
            <p>Your audio stays private in your browser only - never uploaded anywhere. Use Export to save recordings to your device.</p>
        </div>

        <div class="transcription-output" id="transcriptionOutput" style="display: none;">
            <h3>üìù Transcription</h3>
            <div id="transcriptionContent"></div>
        </div>
    </div>

    <button class="theme-toggle" id="themeToggle" title="Toggle theme">üåë</button>

    <!-- Transcription Modal -->
    <div class="modal-overlay" id="transcriptionModal">
        <div class="modal-content">
            <div class="modal-title">üéôÔ∏è Transcribing Audio</div>
            <div class="modal-progress">
                <div class="modal-spinner"></div>
                <div class="modal-text" id="modalProgressText">Initializing...</div>
                <div class="modal-subtext">Please wait while we process your audio</div>
            </div>
        </div>
    </div>

    <script>
        class Dictaphone {
            constructor() {
                this.audioContext = null;
                this.mediaRecorder = null;
                this.stream = null;
                this.audioChunks = [];
                this.isRecording = false;
                this.isPlaying = false;
                this.isPTT = false;
                this.audioBuffer = null;
                this.audioSource = null;
                this.startTime = 0;
                this.pauseTime = 0;
                this.currentPosition = 0;
                this.analyser = null;
                this.dataArray = null;
                this.animationFrame = null;
                this.recordingAnimationFrame = null;
                this.recordingStartTime = 0;
                this.recordingStartPosition = 0;
                this.isDragging = false;
                this.currentThemeMode = 'system'; // Track the current theme mode (system/light/dark)
                
                this.initializeElements();
                this.initializeAudio();
                this.setupEventListeners();
                this.loadFromCache();
                this.initializeTheme();
                this.updateUI();
            }

            initializeElements() {
                this.elements = {
                    recordBtn: document.getElementById('recordBtn'),
                    pttBtn: document.getElementById('pttBtn'),
                    stopBtn: document.getElementById('stopBtn'),
                    playBtn: document.getElementById('playBtn'),
                    skipBackBtn: document.getElementById('skipBackBtn'),
                    skipForwardBtn: document.getElementById('skipForwardBtn'),
                    positionSlider: document.getElementById('positionSlider'),
                    volumeSlider: document.getElementById('volumeSlider'),
                    volumeValue: document.getElementById('volumeValue'),
                    exportBtn: document.getElementById('exportBtn'),
                    eraseBtn: document.getElementById('eraseBtn'),
                    importFile: document.getElementById('importFile'),
                    status: document.getElementById('status'),
                    meterNeedle: document.getElementById('meterNeedle'),
                    currentTime: document.getElementById('currentTime'),
                    totalTime: document.getElementById('totalTime'),
                    themeToggle: document.getElementById('themeToggle'),
                    transcribeTextBtn: document.getElementById('transcribeTextBtn'),
                    transcribeJsonBtn: document.getElementById('transcribeJsonBtn'),
                    transcriptionOutput: document.getElementById('transcriptionOutput'),
                    transcriptionContent: document.getElementById('transcriptionContent'),
                    transcriptionModal: document.getElementById('transcriptionModal'),
                    modalProgressText: document.getElementById('modalProgressText')
                };
            }

            async initializeAudio() {
                try {
                    // Initialize with standard sample rate (browser will handle resampling)
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.gainNode = this.audioContext.createGain();
                    this.gainNode.connect(this.audioContext.destination);
                    
                    // Define optimal sample rate for Whisper (16kHz)
                    this.WHISPER_SAMPLE_RATE = 16000;
                    
                    // Load saved volume level
                    this.loadVolumeFromStorage();
                    
                    // Set up audio analysis for meter (no microphone yet)
                    this.analyser = this.audioContext.createAnalyser();
                    this.analyser.fftSize = 256;
                    this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
                    
                    // Start meter animation (will show idle state when nothing connected)
                    this.startMeterAnimation();
                } catch (error) {
                    console.error('Error initializing audio context:', error);
                    this.updateStatus('Audio initialization failed');
                }
            }

            async requestMicrophoneAccess() {
                if (this.stream && this.microphoneSource) {
                    return true; // Already have access
                }

                try {
                    this.stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: false
                        } 
                    });
                    
                    // Create microphone source
                    this.microphoneSource = this.audioContext.createMediaStreamSource(this.stream);
                    return true;
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.updateStatus('Microphone access denied');
                    return false;
                }
            }

            releaseMicrophoneAccess() {
                if (this.stream) {
                    // Stop all tracks to release microphone
                    this.stream.getTracks().forEach(track => {
                        track.stop();
                    });
                    this.stream = null;
                    this.microphoneSource = null;
                }
            }

            setupEventListeners() {
                // Button events
                this.elements.recordBtn.addEventListener('click', () => this.toggleRecord());
                this.elements.stopBtn.addEventListener('click', () => this.stop());
                this.elements.playBtn.addEventListener('click', () => this.togglePlay());
                this.elements.skipBackBtn.addEventListener('click', () => this.skipBack());
                this.elements.skipForwardBtn.addEventListener('click', () => this.skipForward());
                this.elements.exportBtn.addEventListener('click', () => this.export());
                this.elements.eraseBtn.addEventListener('click', () => this.eraseAll());
                this.elements.importFile.addEventListener('change', (e) => this.import(e));
                this.elements.transcribeTextBtn.addEventListener('click', () => this.transcribeToText());
                this.elements.transcribeJsonBtn.addEventListener('click', () => this.transcribeToJson());

                // PTT events
                this.elements.pttBtn.addEventListener('mousedown', () => this.startPTT());
                this.elements.pttBtn.addEventListener('mouseup', () => this.stopPTT());
                this.elements.pttBtn.addEventListener('mouseleave', () => this.stopPTT());
                this.elements.pttBtn.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                    this.startPTT();
                });
                this.elements.pttBtn.addEventListener('touchend', (e) => {
                    e.preventDefault();
                    this.stopPTT();
                });

                // Slider events
                this.elements.positionSlider.addEventListener('input', (e) => this.onSliderInput(e));
                this.elements.positionSlider.addEventListener('mousedown', (e) => {
                    this.isDragging = true;
                    // Capture current playback position when starting to interact with slider
                    if (this.isPlaying) {
                        this.currentPosition = this.getCurrentPosition();
                    }
                });
                this.elements.positionSlider.addEventListener('mouseup', (e) => {
                    this.isDragging = false;
                    // Slider position updates can now resume
                });
                this.elements.positionSlider.addEventListener('touchstart', (e) => {
                    this.isDragging = true;
                    // Capture current playback position when starting to interact with slider
                    if (this.isPlaying) {
                        this.currentPosition = this.getCurrentPosition();
                    }
                });
                this.elements.positionSlider.addEventListener('touchend', (e) => {
                    this.isDragging = false;
                    // Slider position updates can now resume
                });

                this.elements.volumeSlider.addEventListener('input', (e) => this.updateVolume(e));

                // Theme toggle
                this.elements.themeToggle.addEventListener('click', () => this.toggleTheme());

                // Keyboard events
                document.addEventListener('keydown', (e) => this.handleKeyboard(e));
                document.addEventListener('keyup', (e) => this.handleKeyboardUp(e));

                // Media keys
                navigator.mediaSession.setActionHandler('play', () => this.togglePlay());
                navigator.mediaSession.setActionHandler('pause', () => this.stop());
                navigator.mediaSession.setActionHandler('stop', () => this.stop());

                // Prevent context menu on PTT for better mobile experience
                this.elements.pttBtn.addEventListener('contextmenu', (e) => e.preventDefault());
            }

            handleKeyboard(e) {
                // Don't trigger shortcuts when typing in inputs
                if (e.target.tagName === 'INPUT') return;

                switch(e.key.toLowerCase()) {
                    case 'r':
                        e.preventDefault();
                        this.toggleRecord();
                        break;
                    case 't':
                        e.preventDefault();
                        if (!this.isPTT) {
                            // Check if we should start PTT or transcribe
                            if (this.audioBuffer && !this.isRecording && !this.isPlaying) {
                                this.transcribeToText();
                            } else {
                                this.startPTT();
                            }
                        }
                        break;
                    case ' ':
                        e.preventDefault();
                        this.stop();
                        break;
                    case 'p':
                        e.preventDefault();
                        this.togglePlay();
                        break;
                    case 'arrowleft':
                        e.preventDefault();
                        this.skipBack();
                        break;
                    case 'arrowright':
                        e.preventDefault();
                        this.skipForward();
                        break;
                    case 'i':
                        e.preventDefault();
                        this.elements.importFile.click();
                        break;
                    case 'e':
                        e.preventDefault();
                        this.export();
                        break;
                    case 'j':
                        e.preventDefault();
                        if (this.audioBuffer) this.transcribeToJson();
                        break;
                    case 'delete':
                        e.preventDefault();
                        this.eraseAll();
                        break;
                    case 'm':
                        e.preventDefault();
                        this.toggleTheme();
                        break;
                }
            }

            handleKeyboardUp(e) {
                if (e.key.toLowerCase() === 't' && this.isPTT) {
                    e.preventDefault();
                    this.stopPTT();
                }
            }

            async toggleRecord() {
                if (this.isRecording) {
                    this.stopRecording();
                } else {
                    await this.startRecording();
                }
            }

            async startRecording() {
                if (this.isPlaying) {
                    this.stop();
                }

                // Request microphone access just-in-time
                const micAccess = await this.requestMicrophoneAccess();
                if (!micAccess) {
                    return; // Failed to get microphone access
                }

                // Move position to the end of existing audio before starting recording
                if (this.audioBuffer) {
                    this.currentPosition = this.audioBuffer.duration;
                    this.updatePositionSlider();
                    this.updateTimeLabels();
                }

                // Connect microphone to analyser for meter display during recording
                try {
                    this.microphoneSource.connect(this.analyser);
                } catch (e) {
                    // Microphone might already be connected
                }

                try {
                    this.mediaRecorder = new MediaRecorder(this.stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    this.audioChunks = [];
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };

                    this.mediaRecorder.onstop = () => {
                        this.processRecording();
                    };

                    this.mediaRecorder.start();
                    this.isRecording = true;
                    this.recordingStartTime = this.audioContext.currentTime;
                    this.recordingStartPosition = this.currentPosition;
                    this.updateStatus('Recording...');
                    this.updateUI();
                    this.startRecordingUpdate();
                } catch (error) {
                    console.error('Error starting recording:', error);
                    this.updateStatus('Recording failed');
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.isRecording) {
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    this.stopRecordingUpdate();
                    this.updateStatus('Processing...');
                    this.updateUI(); // Update UI immediately when stopping
                    
                    // Disconnect microphone from analyser when not recording
                    try {
                        this.microphoneSource.disconnect(this.analyser);
                    } catch (e) {
                        // Microphone might already be disconnected
                    }
                    
                    // Release microphone access to stop the recording indicator
                    this.releaseMicrophoneAccess();
                }
            }

            async startPTT() {
                if (!this.isPTT && !this.isRecording) {
                    // Stop playback if it's currently playing
                    if (this.isPlaying) {
                        this.pausePlayback();
                    }
                    
                    this.isPTT = true;
                    await this.startRecording(); // This will request microphone access
                    this.elements.pttBtn.classList.add('recording');
                }
            }

            stopPTT() {
                if (this.isPTT) {
                    this.isPTT = false;
                    this.stopRecording(); // This will release microphone access
                    this.elements.pttBtn.classList.remove('recording');
                    // UI will be updated when processRecording completes
                }
            }

            skipBack() {
                if (!this.audioBuffer) return;
                
                const currentPos = this.isPlaying ? this.getCurrentPosition() : this.currentPosition;
                const newPosition = Math.max(0, currentPos - 10); // Skip back 10 seconds, but not below 0
                
                if (this.isPlaying) {
                    this.seekToPosition(newPosition);
                } else {
                    this.currentPosition = newPosition;
                    this.updatePositionSlider();
                    this.updateTimeLabels();
                }
            }

            skipForward() {
                if (!this.audioBuffer) return;
                
                const currentPos = this.isPlaying ? this.getCurrentPosition() : this.currentPosition;
                const newPosition = Math.min(this.audioBuffer.duration, currentPos + 10); // Skip forward 10 seconds, but not beyond end
                
                if (this.isPlaying) {
                    this.seekToPosition(newPosition);
                } else {
                    this.currentPosition = newPosition;
                    this.updatePositionSlider();
                    this.updateTimeLabels();
                }
            }

            async processRecording() {
                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                
                try {
                    // Convert to AudioBuffer
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const newAudioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                    
                    // Append to existing audio
                    if (this.audioBuffer) {
                        this.audioBuffer = this.concatenateBuffers(this.audioBuffer, newAudioBuffer);
                    } else {
                        this.audioBuffer = newAudioBuffer;
                    }
                    
                    this.saveToCache();
                    this.updateStatus('Ready');
                    this.updateTimeLabels();
                    this.updateUI(); // Ensure UI updates after processing
                } catch (error) {
                    console.error('Error processing recording:', error);
                    this.updateStatus('Processing failed');
                    this.updateUI(); // Update UI even if processing fails
                }
            }

            concatenateBuffers(buffer1, buffer2) {
                const numberOfChannels = Math.min(buffer1.numberOfChannels, buffer2.numberOfChannels);
                const length = buffer1.length + buffer2.length;
                const sampleRate = buffer1.sampleRate;
                
                const result = this.audioContext.createBuffer(numberOfChannels, length, sampleRate);
                
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    const output = result.getChannelData(channel);
                    const input1 = buffer1.getChannelData(channel);
                    const input2 = buffer2.getChannelData(channel);
                    
                    output.set(input1, 0);
                    output.set(input2, buffer1.length);
                }
                
                return result;
            }

            togglePlay() {
                if (this.isPlaying) {
                    this.pausePlayback();
                } else {
                    this.startPlayback();
                }
            }

            async startPlayback() {
                if (!this.audioBuffer || this.isRecording) return;

                try {
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                    }

                    this.audioSource = this.audioContext.createBufferSource();
                    this.audioSource.buffer = this.audioBuffer;
                    
                    // Connect audio source to both gain node and analyser for meter display
                    this.audioSource.connect(this.gainNode);
                    
                    // Disconnect microphone from analyser and connect playback source
                    try {
                        this.microphoneSource.disconnect(this.analyser);
                    } catch (e) {
                        // Microphone might already be disconnected
                    }
                    this.audioSource.connect(this.analyser);

                    const startOffset = this.currentPosition;
                    this.audioSource.start(0, startOffset);
                    this.startTime = this.audioContext.currentTime - startOffset;
                    
                    this.audioSource.onended = () => {
                        if (this.isPlaying) {
                            this.stop();
                        }
                    };

                    this.isPlaying = true;
                    this.updateStatus('Playing');
                    this.updateUI();
                    this.startPositionUpdate();
                } catch (error) {
                    console.error('Error starting playback:', error);
                    this.updateStatus('Playback failed');
                }
            }

            async seekToPosition(position) {
                if (!this.audioBuffer || this.isRecording) return;

                const wasPlaying = this.isPlaying;
                this.currentPosition = position;

                if (wasPlaying) {
                    // Keep isPlaying true throughout the seeking process
                    // to prevent UI from flickering to pause state
                    
                    // Temporarily disable the onended callback to prevent automatic stop
                    if (this.audioSource && this.audioSource.onended) {
                        this.audioSource.onended = null;
                    }
                    
                    // Stop current playback
                    if (this.audioSource) {
                        try {
                            this.audioSource.stop();
                        } catch (e) {
                            // Source might already be stopped
                        }
                        this.audioSource = null;
                    }

                    try {
                        if (this.audioContext.state === 'suspended') {
                            await this.audioContext.resume();
                        }

                        this.audioSource = this.audioContext.createBufferSource();
                        this.audioSource.buffer = this.audioBuffer;
                        
                        // Connect audio source to both gain node and analyser for meter display
                        this.audioSource.connect(this.gainNode);
                        
                        // Disconnect microphone from analyser and connect playback source
                        try {
                            this.microphoneSource.disconnect(this.analyser);
                        } catch (e) {
                            // Microphone might already be disconnected
                        }
                        this.audioSource.connect(this.analyser);

                        const startOffset = this.currentPosition;
                        this.audioSource.start(0, startOffset);
                        this.startTime = this.audioContext.currentTime - startOffset;
                        
                        // Set the onended callback AFTER starting
                        this.audioSource.onended = () => {
                            if (this.isPlaying) {
                                this.stop();
                            }
                        };
                        
                        // Ensure we maintain playing state
                        this.isPlaying = true;
                        
                        // Make sure position updates continue
                        if (!this.animationFrame) {
                            this.startPositionUpdate();
                        }
                        
                    } catch (error) {
                        console.error('Error seeking during playback:', error);
                        this.updateStatus('Seek failed');
                        // If seeking fails, maintain the playing state
                        this.isPlaying = wasPlaying;
                    }
                }
                
                this.updateTimeLabels();
            }

            pausePlayback() {
                if (this.audioSource) {
                    // Disconnect playback source from analyser 
                    try {
                        this.audioSource.disconnect(this.analyser);
                    } catch (e) {
                        // Source might already be disconnected
                    }
                    
                    this.audioSource.stop();
                    this.audioSource = null;
                }
                this.currentPosition = this.getCurrentPosition();
                this.isPlaying = false;
                this.updateStatus('Paused');
                this.updateUI();
                this.stopPositionUpdate();
            }

            stop() {
                if (this.isRecording) {
                    this.stopRecording();
                }
                
                if (this.isPlaying) {
                    this.pausePlayback();
                }
                
                if (this.isPTT) {
                    this.stopPTT();
                }
                
                // Ensure all audio sources are disconnected from analyser when stopped
                if (this.audioSource) {
                    try {
                        this.audioSource.disconnect(this.analyser);
                    } catch (e) {
                        // Source might already be disconnected
                    }
                }
                if (this.microphoneSource) {
                    try {
                        this.microphoneSource.disconnect(this.analyser);
                    } catch (e) {
                        // Microphone might already be disconnected
                    }
                }
                
                // Release microphone when stopping to clear recording indicator
                if (!this.isRecording && !this.isPTT) {
                    this.releaseMicrophoneAccess();
                }
                
                this.currentPosition = 0;
                this.updatePositionSlider();
                this.updateTimeLabels();
                this.updateStatus('Ready');
                this.updateUI();
            }

            onSliderInput(e) {
                if (this.audioBuffer) {
                    const position = (e.target.value / 100) * this.audioBuffer.duration;
                    
                    if (this.isPlaying) {
                        // Use seekToPosition to maintain playback state
                        this.seekToPosition(position);
                    } else {
                        // Just update position when not playing
                        this.currentPosition = position;
                        this.updateTimeLabels();
                    }
                }
            }

            updateVolume(e) {
                const volume = e.target.value / 100;
                this.gainNode.gain.value = volume;
                this.elements.volumeValue.textContent = `${e.target.value}%`;
                
                // Save volume to localStorage
                localStorage.setItem('dictaphone-volume', e.target.value);
            }

            getCurrentPosition() {
                if (this.isPlaying && this.audioContext && this.audioSource) {
                    return this.audioContext.currentTime - this.startTime;
                }
                return this.currentPosition;
            }

            startPositionUpdate() {
                const updatePosition = () => {
                    if (this.isPlaying) {
                        const position = this.getCurrentPosition();
                        if (!this.isDragging) {
                            this.updatePositionSlider();
                        }
                        this.updateTimeLabels();
                        this.animationFrame = requestAnimationFrame(updatePosition);
                    }
                };
                updatePosition();
            }

            startRecordingUpdate() {
                const updateRecording = () => {
                    if (this.isRecording) {
                        // Update the slider max to show growing audio length
                        const recordingDuration = this.audioContext.currentTime - this.recordingStartTime;
                        const newTotalDuration = this.recordingStartPosition + recordingDuration;
                        
                        // Update time labels to show the growing total duration
                        this.elements.currentTime.textContent = this.formatTime(this.currentPosition);
                        this.elements.totalTime.textContent = this.formatTime(newTotalDuration);
                        
                        // Update the slider max value but keep position at the recording start point
                        const percentage = this.audioBuffer ? 
                            (this.currentPosition / newTotalDuration) * 100 : 0;
                        this.elements.positionSlider.value = Math.min(percentage, 100);
                        
                        this.recordingAnimationFrame = requestAnimationFrame(updateRecording);
                    }
                };
                updateRecording();
            }

            stopRecordingUpdate() {
                if (this.recordingAnimationFrame) {
                    cancelAnimationFrame(this.recordingAnimationFrame);
                    this.recordingAnimationFrame = null;
                }
            }

            stopPositionUpdate() {
                if (this.animationFrame) {
                    cancelAnimationFrame(this.animationFrame);
                    this.animationFrame = null;
                }
            }

            updatePositionSlider() {
                if (this.audioBuffer && !this.isDragging) {
                    const position = this.getCurrentPosition();
                    const percentage = (position / this.audioBuffer.duration) * 100;
                    this.elements.positionSlider.value = Math.min(percentage, 100);
                } else if (!this.audioBuffer) {
                    // No audio buffer - reset slider to 0
                    this.elements.positionSlider.value = 0;
                }
            }

            updateTimeLabels() {
                if (this.audioBuffer) {
                    const current = this.getCurrentPosition();
                    const total = this.audioBuffer.duration;
                    
                    this.elements.currentTime.textContent = this.formatTime(current);
                    this.elements.totalTime.textContent = this.formatTime(total);
                } else {
                    // No audio buffer - reset time labels to 0:00
                    this.elements.currentTime.textContent = '0:00';
                    this.elements.totalTime.textContent = '0:00';
                }
            }

            formatTime(seconds) {
                const mins = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${mins}:${secs.toString().padStart(2, '0')}`;
            }

            startMeterAnimation() {
                const updateMeter = () => {
                    if (this.analyser && this.dataArray) {
                        this.analyser.getByteFrequencyData(this.dataArray);
                        
                        // Calculate average volume
                        let sum = 0;
                        for (let i = 0; i < this.dataArray.length; i++) {
                            sum += this.dataArray[i];
                        }
                        const average = sum / this.dataArray.length;
                        
                        // Check if we have any meaningful audio input connected
                        const hasAudioInput = this.isRecording || this.isPlaying;
                        
                        if (hasAudioInput) {
                            // Convert to rotation (-90 to 90 degrees) when we have active audio
                            const rotation = (average / 255) * 180 - 90;
                            this.elements.meterNeedle.style.transform = `translateX(-50%) rotate(${rotation}deg)`;
                        } else {
                            // Show idle state (needle at bottom) when no active audio
                            this.elements.meterNeedle.style.transform = `translateX(-50%) rotate(-90deg)`;
                        }
                    }
                    requestAnimationFrame(updateMeter);
                };
                updateMeter();
            }

            async export() {
                if (!this.audioBuffer) {
                    this.updateStatus('No audio to export');
                    return;
                }

                try {
                    this.updateStatus('Exporting...');
                    
                    // Convert AudioBuffer to WAV
                    const wavBuffer = this.audioBufferToWav(this.audioBuffer);
                    const blob = new Blob([wavBuffer], { type: 'audio/wav' });
                    
                    // Create download
                    const now = new Date();
                    const filename = `audio_${now.getFullYear()}-${String(now.getMonth() + 1).padStart(2, '0')}-${String(now.getDate()).padStart(2, '0')}_${String(now.getHours()).padStart(2, '0')}${String(now.getMinutes()).padStart(2, '0')}.wav`;
                    
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.href = url;
                    a.download = filename;
                    document.body.appendChild(a);
                    a.click();
                    document.body.removeChild(a);
                    URL.revokeObjectURL(url);
                    
                    this.updateStatus('Exported successfully');
                } catch (error) {
                    console.error('Export error:', error);
                    this.updateStatus('Export failed');
                }
            }

            audioBufferToWav(buffer) {
                const length = buffer.length;
                const numberOfChannels = buffer.numberOfChannels;
                const sampleRate = buffer.sampleRate;
                const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
                const view = new DataView(arrayBuffer);
                
                // WAV header
                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };
                
                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * numberOfChannels * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, numberOfChannels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * numberOfChannels * 2, true);
                view.setUint16(32, numberOfChannels * 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * numberOfChannels * 2, true);
                
                // Convert audio data
                let offset = 44;
                for (let i = 0; i < length; i++) {
                    for (let channel = 0; channel < numberOfChannels; channel++) {
                        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
                        view.setInt16(offset, sample * 0x7FFF, true);
                        offset += 2;
                    }
                }
                
                return arrayBuffer;
            }

            async import(event) {
                const file = event.target.files[0];
                if (!file) return;

                try {
                    this.updateStatus('Importing...');
                    
                    // Clear cached audio when importing - user expects fresh start
                    await this.clearCache();
                    
                    const arrayBuffer = await file.arrayBuffer();
                    this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                    this.currentPosition = 0;
                    await this.saveToCache(); // Save to cache
                    this.updateStatus('Imported successfully');
                    this.updateTimeLabels();
                    this.updatePositionSlider();
                    this.updateUI(); // Ensure UI updates after import to enable buttons
                } catch (error) {
                    console.error('Import error:', error);
                    this.updateStatus('Import failed');
                }
                
                // Clear the file input
                event.target.value = '';
            }

            async eraseAll() {
                if (confirm('Are you sure you want to erase all audio? This cannot be undone.')) {
                    // Stop any ongoing playback, recording, or PTT first
                    this.stop();
                    
                    // Clear audio buffer and reset position
                    this.audioBuffer = null;
                    this.currentPosition = 0;
                    
                    // Clear cached data
                    await this.clearCache();
                    
                    // Update UI and status
                    this.updateStatus('Audio erased');
                    this.updateTimeLabels();
                    this.updatePositionSlider();
                    this.updateUI();
                }
            }

            async saveToCache() {
                if (this.audioBuffer) {
                    try {
                        // Convert AudioBuffer to WAV blob for caching
                        const wavBuffer = this.audioBufferToWav(this.audioBuffer);
                        const blob = new Blob([wavBuffer], { type: 'audio/wav' });
                        
                        // Create a response object to store in cache
                        const response = new Response(blob, {
                            headers: {
                                'Content-Type': 'audio/wav',
                                'Content-Length': blob.size.toString()
                            }
                        });
                        
                        // Open cache and store the audio
                        const cache = await caches.open('dictaphone-cache');
                        await cache.put('dictaphone-audio', response);
                        
                    } catch (error) {
                        console.warn('Error saving to cache:', error);
                        // Continue working normally, just without persistence
                    }
                }
            }

            async loadFromCache() {
                try {
                    const cache = await caches.open('dictaphone-cache');
                    const response = await cache.match('dictaphone-audio');
                    
                    if (response) {
                        this.updateStatus('Loading saved audio...');
                        const arrayBuffer = await response.arrayBuffer();
                        this.audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                        
                        this.updateTimeLabels();
                        this.updateStatus('Audio loaded from previous session');
                        this.updateUI();
                    }
                } catch (error) {
                    console.error('Error loading from cache:', error);
                    // Clear corrupted cache
                    await this.clearCache();
                }
            }

            loadVolumeFromStorage() {
                try {
                    const savedVolume = localStorage.getItem('dictaphone-volume');
                    if (savedVolume !== null) {
                        const volumeValue = parseInt(savedVolume, 10);
                        if (volumeValue >= 0 && volumeValue <= 100) {
                            this.elements.volumeSlider.value = volumeValue;
                            this.elements.volumeValue.textContent = `${volumeValue}%`;
                            this.gainNode.gain.value = volumeValue / 100;
                        }
                    }
                } catch (error) {
                    console.error('Error loading volume from storage:', error);
                    // Use default volume if loading fails
                }
            }

            async clearCache() {
                try {
                    const cache = await caches.open('dictaphone-cache');
                    await cache.delete('dictaphone-audio');
                } catch (error) {
                    console.error('Error clearing cache:', error);
                }
            }

            initializeTheme() {
                const savedTheme = localStorage.getItem('dictaphone-theme');
                if (savedTheme && ['light', 'dark'].includes(savedTheme)) {
                    // Explicit theme was saved
                    this.currentThemeMode = savedTheme;
                    document.body.setAttribute('data-theme', savedTheme);
                    this.updateThemeIcon(savedTheme);
                } else {
                    // Default to system preference
                    this.currentThemeMode = 'system';
                    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
                    const theme = prefersDark ? 'dark' : 'light';
                    document.body.setAttribute('data-theme', theme);
                    this.updateThemeIcon('system');
                }
                
                // Listen for system theme changes
                const mediaQuery = window.matchMedia('(prefers-color-scheme: dark)');
                mediaQuery.addEventListener('change', (e) => {
                    if (this.currentThemeMode === 'system') {
                        document.body.setAttribute('data-theme', e.matches ? 'dark' : 'light');
                    }
                });
            }

            toggleTheme() {
                // Cycle through: system -> light -> dark -> system
                if (this.currentThemeMode === 'system') {
                    this.currentThemeMode = 'light';
                    document.body.setAttribute('data-theme', 'light');
                    this.updateThemeIcon('light');
                    localStorage.setItem('dictaphone-theme', 'light');
                } else if (this.currentThemeMode === 'light') {
                    this.currentThemeMode = 'dark';
                    document.body.setAttribute('data-theme', 'dark');
                    this.updateThemeIcon('dark');
                    localStorage.setItem('dictaphone-theme', 'dark');
                } else {
                    this.currentThemeMode = 'system';
                    const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
                    document.body.setAttribute('data-theme', prefersDark ? 'dark' : 'light');
                    this.updateThemeIcon('system');
                    localStorage.removeItem('dictaphone-theme'); // Remove explicit theme to use system
                }
            }

            updateThemeIcon(mode) {
                const icons = {
                    'system': 'üåì', // Half moon for system (auto)
                    'light': '‚òÄÔ∏è',  // Sun for light mode
                    'dark': 'üåô'    // Crescent moon for dark mode
                };
                this.elements.themeToggle.textContent = icons[mode] || icons.system;
                
                // Update title to show current mode
                const titles = {
                    'system': 'Theme: System (Auto)',
                    'light': 'Theme: Light', 
                    'dark': 'Theme: Dark'
                };
                this.elements.themeToggle.title = titles[mode] || titles.system;
            }

            updateStatus(message) {
                this.elements.status.textContent = message;
                this.elements.status.className = 'status';
                
                if (message === 'Recording...') {
                    this.elements.status.classList.add('recording');
                } else if (message === 'Playing') {
                    this.elements.status.classList.add('playing');
                }
            }

            showTranscriptionModal(message = 'Initializing...') {
                this.elements.modalProgressText.textContent = message;
                this.elements.transcriptionModal.classList.add('show');
                document.body.style.overflow = 'hidden'; // Prevent background scrolling
            }

            hideTranscriptionModal() {
                this.elements.transcriptionModal.classList.remove('show');
                document.body.style.overflow = ''; // Restore scrolling
            }

            updateModalProgress(message) {
                this.elements.modalProgressText.textContent = message;
            }

            // Ensure transcription pipeline is loaded (singleton)
            async ensurePipeline() {
                if (window.transcriptionPipeline) return window.transcriptionPipeline;
                if (window.isTranscriptionModelLoading) {
                    while (window.isTranscriptionModelLoading) {
                        await new Promise(r => setTimeout(r, 100));
                    }
                    return window.transcriptionPipeline;
                }
                window.isTranscriptionModelLoading = true;
                this.updateModalProgress('Loading model...');
                const { pipeline } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2/dist/transformers.min.js');
                window.transcriptionPipeline = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en', {
                    quantized: false,
                    progress_callback: (progress) => {
                        if (progress.status === 'progress') {
                            const percent = Math.min(Math.round(progress.progress * 100), 100);
                            const fileName = progress.file ? progress.file.split('/').pop() : 'model';
                            this.updateModalProgress(`Loading ${fileName} (${percent}%)`);
                        }
                    }
                });
                window.isTranscriptionModelLoading = false;
                return window.transcriptionPipeline;
            }

            // Preprocess AudioBuffer -> Float32Array 16k mono normalized (only boost)
            preprocessAudio() {
                if (!this.audioBuffer) throw new Error('No audio buffer');
                const originalSampleRate = this.audioBuffer.sampleRate;
                const targetSampleRate = 16000;
                let mono;
                if (this.audioBuffer.numberOfChannels === 2) {
                    const SCALING_FACTOR = Math.sqrt(2);
                    const left = this.audioBuffer.getChannelData(0);
                    const right = this.audioBuffer.getChannelData(1);
                    mono = new Float32Array(left.length);
                    for (let i = 0; i < left.length; i++) mono[i] = SCALING_FACTOR * (left[i] + right[i]) / 2;
                } else {
                    mono = new Float32Array(this.audioBuffer.getChannelData(0));
                }
                let audioData;
                if (originalSampleRate !== targetSampleRate) {
                    const ratio = originalSampleRate / targetSampleRate;
                    const newLength = Math.round(mono.length / ratio);
                    audioData = new Float32Array(newLength);
                    for (let i = 0; i < newLength; i++) {
                        const origIndex = i * ratio;
                        const i0 = Math.floor(origIndex);
                        const i1 = Math.min(i0 + 1, mono.length - 1);
                        const t = origIndex - i0;
                        audioData[i] = mono[i0] * (1 - t) + mono[i1] * t;
                    }
                } else {
                    audioData = mono;
                }
                let maxAmplitude = 0; let sumSquares = 0;
                for (let i = 0; i < audioData.length; i++) { const v = Math.abs(audioData[i]); if (v > maxAmplitude) maxAmplitude = v; sumSquares += audioData[i]*audioData[i]; }
                const targetAmplitude = 0.8;
                if (maxAmplitude > 0 && maxAmplitude < targetAmplitude * 0.98) {
                    const gain = targetAmplitude / maxAmplitude;
                    for (let i = 0; i < audioData.length; i++) audioData[i] *= gain;
                }
                const rms = Math.sqrt(sumSquares / audioData.length);
                return { audioData, stats: { originalSampleRate, targetSampleRate, resampled: originalSampleRate !== targetSampleRate, length: audioData.length, duration: this.audioBuffer.duration, peak: maxAmplitude, rms } };
            }

            // Unified streaming transcription producing incremental UI updates
            async streamTranscription(mode = 'text') {
                if (!this.audioBuffer) throw new Error('No audio');
                this.showTranscriptionModal('Preparing...');
                this.elements.transcriptionOutput.style.display = 'block';
                const pipeline = await this.ensurePipeline();
                this.updateModalProgress('Preprocessing audio...');
                await new Promise(r => setTimeout(r, 30)); // allow paint
                const { audioData, stats } = this.preprocessAudio();
                console.log('Preprocess stats (stream):', stats);
                this.updateModalProgress('Segmenting audio...');
                await new Promise(r => setTimeout(r, 10));

                // Prepare UI container for streaming
                const container = this.elements.transcriptionContent;
                const startTime = performance.now();
                container.innerHTML = `<div style="font-weight:bold;margin-bottom:8px;">Streaming ${mode === 'json' ? 'JSON' : 'text'} transcription...</div>`;
                const outputArea = document.createElement('div');
                outputArea.style.cssText = 'font-family: monospace; white-space: pre-wrap; line-height:1.5; max-height:300px; overflow-y:auto; padding:8px; border:1px solid var(--border-color); border-radius:6px; background:var(--bg-color);';
                container.appendChild(outputArea);
                const progressLine = document.createElement('div');
                progressLine.style.cssText = 'margin-top:6px; font-size:12px; opacity:0.8;';
                container.appendChild(progressLine);

                // Segmentation parameters
                const sampleRate = 16000; // after preprocessing
                const segmentSeconds = 30; // 30s chunks
                const segmentSamples = segmentSeconds * sampleRate;
                const totalSamples = audioData.length;
                const totalSegments = Math.ceil(totalSamples / segmentSamples);
                const baseParams = { top_k: 0, do_sample: false, language: 'english', task: 'transcribe', temperature: 0 };

                let accumulatedText = '';
                const jsonChunks = [];
                let lastEmitTime = 0;

                for (let segIndex = 0; segIndex < totalSegments; segIndex++) {
                    const start = segIndex * segmentSamples;
                    const end = Math.min(start + segmentSamples, totalSamples);
                    const segment = audioData.subarray(start, end);
                    const segStartSec = start / sampleRate;
                    const segEndSec = end / sampleRate;
                    this.updateModalProgress(`Transcribing segment ${segIndex + 1}/${totalSegments} (${segStartSec.toFixed(1)}-${segEndSec.toFixed(1)}s)`);
                    progressLine.textContent = `Segment ${segIndex + 1}/${totalSegments} (${((segEndSec)/stats.duration*100).toFixed(1)}%)`;

                    // First try with timestamps (word) for richer JSON, fallback to raw minimal if empty
                    let result = null;
                    try {
                        result = await pipeline(segment, { ...baseParams, return_timestamps: (mode === 'json') ? 'word' : true });
                        if (!result?.text || !result.text.trim()) {
                            console.warn('Empty result with timestamps, retrying raw minimal');
                            result = await pipeline(segment);
                        }
                    } catch (e) {
                        console.warn('Segment inference error (primary), retrying raw minimal', e);
                        result = await pipeline(segment);
                    }
                    if (!result?.text || !result.text.trim()) {
                        console.warn('Segment still empty after fallback, inserting placeholder');
                        result = { text: '', chunks: [] };
                    }

                    const cleaned = result.text;
                    if (cleaned) {
                        if (accumulatedText && !/\s$/.test(accumulatedText)) accumulatedText += ' ';
                        accumulatedText += cleaned;
                    }

                    // Build JSON chunk (approx timestamps if missing)
                    if (mode === 'json') {
                        if (Array.isArray(result.chunks) && result.chunks.length) {
                            // adjust chunk timestamps by segment offset
                            for (const ch of result.chunks) {
                                const ts = ch.timestamp || ch.timestamps || [0,0];
                                const off = [ (ts[0]||0)+segStartSec, (ts[1]||0)+segStartSec ];
                                jsonChunks.push({ text: ch.text || ch.chunk || '', timestamp: off });
                            }
                        } else if (cleaned) {
                            jsonChunks.push({ text: cleaned, timestamp: [segStartSec, segEndSec] });
                        }
                    }

                    // Incremental UI update
                    if (mode === 'text') {
                        outputArea.textContent = accumulatedText;
                    } else {
                        // Show compact JSON preview live
                        const liveObj = { text: accumulatedText, chunks: jsonChunks.slice(-10), total_chunks: jsonChunks.length };
                        outputArea.textContent = JSON.stringify(liveObj, null, 2);
                    }
                    // Auto-scroll output area occasionally
                    const now = performance.now();
                    if (now - lastEmitTime > 500) {
                        outputArea.scrollTop = outputArea.scrollHeight;
                        lastEmitTime = now;
                        await new Promise(r => setTimeout(r, 10)); // yield
                    }
                }

                this.hideTranscriptionModal();
                progressLine.textContent = `Completed in ${((performance.now()-startTime)/1000).toFixed(1)}s`;                
                this.updateStatus('Transcription complete');

                // Finalize JSON full object if requested
                if (mode === 'json') {
                    const finalObj = { text: accumulatedText, chunks: jsonChunks, duration: stats.duration, generated_at: new Date().toISOString() };
                    outputArea.textContent = JSON.stringify(finalObj, null, 2);
                }

                // Add copy/download buttons
                const btns = document.createElement('div');
                btns.style.cssText = 'margin-top:10px; text-align:center;';
                const copyBtn = document.createElement('button');
                copyBtn.textContent = 'üìã Copy';
                copyBtn.style.cssText = 'padding:6px 14px; margin-right:8px;';
                copyBtn.onclick = () => navigator.clipboard.writeText(mode === 'json' ? outputArea.textContent : accumulatedText);
                const dlBtn = document.createElement('button');
                dlBtn.textContent = 'üíæ Download';
                dlBtn.style.cssText = 'padding:6px 14px;';
                dlBtn.onclick = () => {
                    const data = mode === 'json' ? outputArea.textContent : accumulatedText;
                    this.downloadTranscription(data, mode === 'json' ? 'transcript.json' : 'transcript.txt', mode === 'json' ? 'application/json' : 'text/plain');
                };
                btns.appendChild(copyBtn); btns.appendChild(dlBtn); container.appendChild(btns);
            }

            async transcribeToText() {
                if (!this.audioBuffer) { this.updateStatus('No audio to transcribe'); return; }
                try { await this.streamTranscription('text'); }
                catch (error) {
                    console.error('Transcription error (stream text):', error);
                    this.hideTranscriptionModal();
                    this.updateStatus('Transcription failed');
                    this.elements.transcriptionContent.innerHTML = `<div style="color: var(--button-danger); padding: 20px; text-align: left; font-family: monospace; white-space: pre-wrap;">‚ùå Transcription failed: ${error.message}\n\n${error.stack || ''}</div>`;
                }
            }

            async transcribeToJson() {
                if (!this.audioBuffer) { this.updateStatus('No audio to transcribe'); return; }
                try { await this.streamTranscription('json'); }
                catch (error) {
                    console.error('Transcription error (stream json):', error);
                    this.hideTranscriptionModal();
                    this.updateStatus('Transcription failed');
                    this.elements.transcriptionContent.innerHTML = `<div style=\"color: var(--button-danger); padding: 20px; text-align: left; font-family: monospace; white-space: pre-wrap;\">‚ùå Transcription failed: ${error.message}\\n\\n${error.stack || ''}</div>`;
                }
            }

            displayTranscriptionResult(result, format) {
                console.log('Displaying transcription result:', { result, format });
                
                let content = '';
                
                if (format === 'text') {
                    // Simple text format - handle different result structures
                    const transcribedText = (result?.text || 'No transcription available').toString();
                    content = `
                        <div class="transcription-chunk">
                            <div style="margin-bottom: 10px; font-weight: bold;">üìù Transcribed Text:</div>
                            <div style="font-family: sans-serif; line-height: 1.6; max-height: 300px; overflow-y: auto; padding: 10px; border: 1px solid var(--border-color); border-radius: 6px; background: var(--bg-color);">${transcribedText}</div>
                        </div>
                        <div style="text-align: center; margin-top: 15px;">
                            <button onclick="navigator.clipboard.writeText('${transcribedText.replace(/'/g, "\\'")}').then(() => alert('Text copied to clipboard!'))" 
                                    style="padding: 8px 16px; background: var(--button-success); color: white; border: none; border-radius: 6px; cursor: pointer;">
                                üìã Copy Text
                            </button>
                            <button onclick="window.downloadTranscription('${transcribedText.replace(/'/g, "\\'")}', 'transcript.txt', 'text/plain')" 
                                    style="padding: 8px 16px; background: var(--button-bg); color: white; border: none; border-radius: 6px; cursor: pointer; margin-left: 10px;">
                                üíæ Download TXT
                            </button>
                        </div>
                    `;
                } else {
                    // JSON format with timestamps - handle different result structures
                    const jsonData = {
                        text: result?.text || result || 'No transcription available',
                        chunks: result?.chunks || result?.chunks || [{
                            text: result?.text || result || 'No transcription available',
                            timestamp: [0, this.audioBuffer?.duration || 0]
                        }],
                        duration: this.audioBuffer?.duration || 0,
                        transcribed_at: new Date().toISOString(),
                        raw_result: result // Include the raw result for debugging
                    };
                    
                    const jsonString = JSON.stringify(jsonData, null, 2);
                    
                    content = `
                        <div class="transcription-chunk">
                            <div style="margin-bottom: 10px; font-weight: bold;">üìÑ JSON Output:</div>
                            <pre style="white-space: pre-wrap; font-size: 12px; max-height: 300px; overflow-y: auto; padding: 10px; border: 1px solid var(--border-color); border-radius: 6px; background: var(--bg-color);">${jsonString}</pre>
                        </div>
                        <div style="text-align: center; margin-top: 15px;">
                            <button onclick="navigator.clipboard.writeText('${jsonString.replace(/'/g, "\\'")}').then(() => alert('JSON copied to clipboard!'))" 
                                    style="padding: 8px 16px; background: var(--button-success); color: white; border: none; border-radius: 6px; cursor: pointer;">
                                üìã Copy JSON
                            </button>
                            <button onclick="window.downloadTranscription('${jsonString.replace(/'/g, "\\'")}', 'transcript.json', 'application/json')" 
                                    style="padding: 8px 16px; background: var(--button-bg); color: white; border: none; border-radius: 6px; cursor: pointer; margin-left: 10px;">
                                üíæ Download JSON
                            </button>
                        </div>
                    `;
                }
                
                this.elements.transcriptionContent.innerHTML = content;
                
                // Scroll to transcription panel so user can see the results
                setTimeout(() => {
                    this.elements.transcriptionOutput.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }, 100); // Small delay to ensure content is rendered
            }

            downloadTranscription(content, filename, mimeType) {
                const blob = new Blob([content], { type: mimeType });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = filename;
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }

            updateUI() {
                // Update button states - Record button should only show as recording for regular recording, not PTT
                this.elements.recordBtn.classList.toggle('recording', this.isRecording && !this.isPTT);
                this.elements.playBtn.textContent = this.isPlaying ? '‚è∏Ô∏è Pause' : '‚ñ∂Ô∏è Play';
                
                // Disable slider only during recording, not during playback
                this.elements.positionSlider.disabled = this.isRecording;
                
                // Update button availability
                const hasAudio = !!this.audioBuffer;
                this.elements.playBtn.disabled = !hasAudio || this.isRecording;
                this.elements.skipBackBtn.disabled = !hasAudio || this.isRecording;
                this.elements.skipForwardBtn.disabled = !hasAudio || this.isRecording;
                this.elements.exportBtn.disabled = !hasAudio;
                this.elements.eraseBtn.disabled = !hasAudio;
                this.elements.transcribeTextBtn.disabled = !hasAudio || this.isRecording;
                this.elements.transcribeJsonBtn.disabled = !hasAudio || this.isRecording;
                
                // Mutual exclusion: Record and PTT should disable each other
                this.elements.recordBtn.disabled = this.isPTT;
                this.elements.pttBtn.disabled = this.isRecording && !this.isPTT;
                
                // PTT visual feedback
                if (this.isPTT && this.isRecording) {
                    this.elements.pttBtn.classList.add('recording');
                } else {
                    this.elements.pttBtn.classList.remove('recording');
                }
            }
        }

        // Initialize the dictaphone when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            const dictaphone = new Dictaphone();
            
            // Make downloadTranscription method globally accessible for inline onclick handlers
            window.downloadTranscription = (content, filename, mimeType) => {
                dictaphone.downloadTranscription(content, filename, mimeType);
            };
        });
    </script>
</body>
</html>
